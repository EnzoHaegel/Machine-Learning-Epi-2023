{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Dataset Generation\n",
    "\n",
    "## The goal\n",
    "The goal of this exercise is to work with statistical notions such as mean, standard deviation, and correlation.\n",
    "\n",
    "Write a file named artificial_dataset.py that generates a numerical dataset with 300 datapoints (i.e. lines) and at least 6 columns and saves it to a csv file named artificial_dataset.csv.\n",
    "The columns must satisfy the following requirements :\n",
    "- they must all have a different mean\n",
    "- they must all have a different standard deviation (English for \"Ã©cart type\")\n",
    "- at least one column should contain integers.\n",
    "- at least one column should contain floats.\n",
    "- one column must have a mean close to 2.5.\n",
    "- some columns must be positively correlated.\n",
    "- some columns must be negatively correlated.\n",
    "- some columns must have a correlation close to 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "First, let's import the necessary libraries for our data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation Functions\n",
    "\n",
    "Below are the functions that will be used to generate correlated data and create our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correlated_data(n: int, mean1: float, std1: float, mean2: float, std2: float, correlation: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Generates a sample of n points with a specified correlation.\n",
    "    \n",
    "    :param n: Number of datapoints\n",
    "    :param mean1: Mean of the first variable\n",
    "    :param std1: Standard deviation of the first variable\n",
    "    :param mean2: Mean of the second variable\n",
    "    :param std2: Standard deviation of the second variable\n",
    "    :param correlation: Target correlation between the two variables\n",
    "    :return: n x 2 matrix with the correlated variables\n",
    "    \"\"\"\n",
    "    cov_matrix = [[std1**2, correlation*std1*std2], [correlation*std1*std2, std2**2]]\n",
    "    sample = np.random.multivariate_normal([mean1, mean2], cov_matrix, n)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define the function to create our full dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataset with 6 features and 1 target variable.\n",
    "\n",
    "    :param n: Number of datapoints\n",
    "    :return: Pandas DataFrame with the dataset\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "\n",
    "    means = [1, 2.5, 5, 10, 20, 50]\n",
    "    stds = [0.5, 1, 2, 4, 8, 16]\n",
    "\n",
    "    # Create positively correlated data for columns 3 and 4\n",
    "    columns = [None] * 6  # Initialize list for columns\n",
    "    columns[2], columns[3] = generate_correlated_data(n, means[2], stds[2], means[3], stds[3], 0.8).T\n",
    "\n",
    "    # Generate negatively correlated data for columns 2 and 5\n",
    "    columns[1], columns[4] = generate_correlated_data(n, means[1], stds[1], means[4], stds[4], -0.8).T\n",
    "\n",
    "    # Generate the rest of the columns with different means and standard deviations\n",
    "    for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "        if columns[i] is None:\n",
    "            columns[i] = np.random.normal(mean, std, n)\n",
    "    columns[0] = np.round(columns[0]).astype(int)  # Ensures column has integer data\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data=np.array(columns).T, columns=[f'feature_{i}' for i in range(1, 7)])\n",
    "\n",
    "    # Shuffle the last column until low correlation is achieved with all other columns\n",
    "    min_correlation = 0.1\n",
    "    attempts = 0\n",
    "    max_attempts = 1000  # Set a maximum number of shuffling attempts\n",
    "\n",
    "    while attempts < max_attempts and min_correlation >= 0.1:\n",
    "        np.random.shuffle(df['feature_6'].values)  # Shuffle feature_6 inplace\n",
    "        max_correlation = df.corr().abs().loc['feature_6'].drop('feature_6').max()\n",
    "        if max_correlation < min_correlation:\n",
    "            min_correlation = max_correlation\n",
    "        attempts += 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "\n",
    "The main function orchestrates the data generation process and saves the dataset to a CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to generate and save the dataset.\n",
    "    \"\"\"\n",
    "    n = 300  # number of datapoints\n",
    "    df = create_dataset(n)\n",
    "    df.to_csv('artificial_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Main\n",
    "\n",
    "With everything set up, let's execute the main function to generate and save our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Classes and Functions\n",
    "\n",
    "Before we perform checks on the dataset, let's define some utility classes and functions.\n",
    "The `bcolors` class will allow us to print colored text in the notebook's output to make it more readable.\n",
    "We also define functions to check whether a DataFrame contains integer data and to print messages in color based on a condition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation Functions\n",
    "\n",
    "Now we have functions to check certain conditions within our dataset like the uniqueness of means and standard deviations, data types of the columns, and correlations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_integers(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"\n",
    "    :param df: DataFrame to check\n",
    "    :return: True if at least one column contains integers, False otherwise\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_integer_dtype(df[col]):\n",
    "            return True\n",
    "        if all(df[col] == df[col].astype(int)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def print_colored_message(condition, true_message, false_message):\n",
    "    \"\"\"\n",
    "    Prints a message in green if condition is True, in red otherwise.\n",
    "\n",
    "    :param condition: Condition to check\n",
    "    :param true_message: Message to print if condition is True\n",
    "    :param false_message: Message to print if condition is False\n",
    "    \"\"\"\n",
    "    if condition:\n",
    "        print(f\"{bcolors.OKGREEN}{true_message}{bcolors.ENDC}\")\n",
    "    else:\n",
    "        print(f\"{bcolors.FAIL}{false_message}{bcolors.ENDC}\")\n",
    "\n",
    "def check_dataset_conditions(file_path: str):\n",
    "    \"\"\"\n",
    "    Checks the conditions of the dataset.\n",
    "    :param file_path: Path to the dataset\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Check for unique means\n",
    "    means = df.mean()\n",
    "    print(f\"{bcolors.HEADER}\\nMeans:\\n{bcolors.ENDC}\", means)\n",
    "    all_means_different = len(set(means.round(3))) == len(means)\n",
    "    print_colored_message(all_means_different, \"All columns have different means: True\", \"All columns have different means: False\")\n",
    "\n",
    "    # Check for unique standard deviations\n",
    "    stds = df.std()\n",
    "    print(f\"{bcolors.HEADER}\\nStandard Deviations:\\n{bcolors.ENDC}\", stds)\n",
    "    all_stds_different = len(set(stds.round(3))) == len(stds)\n",
    "    print_colored_message(all_stds_different, \"All columns have different standard deviations: True\", \"All columns have different standard deviations: False\")\n",
    "\n",
    "    # Check for at least one integer column\n",
    "    has_integer_column = check_integers(df)\n",
    "    print_colored_message(has_integer_column, \"At least one column contains integers: True\", \"At least one column contains integers: False\")\n",
    "\n",
    "    # Check for at least one float column\n",
    "    has_float_column = any(df.dtypes == 'float')\n",
    "    print_colored_message(has_float_column, \"At least one column contains floats: True\", \"At least one column contains floats: False\")\n",
    "\n",
    "    # Check for a column with mean close to 2.5\n",
    "    mean_close_to_25 = any(np.isclose(means, 2.5, atol=0.1))\n",
    "    print_colored_message(mean_close_to_25, \"One column has a mean close to 2.5: True\", \"One column has a mean close to 2.5: False\")\n",
    "\n",
    "    # Check correlations\n",
    "    corr_matrix = df.corr()\n",
    "    print(f\"{bcolors.HEADER}\\nCorrelation Matrix:\\n{bcolors.ENDC}\", corr_matrix)\n",
    "    positive_correlations = corr_matrix.values[np.triu_indices_from(corr_matrix.values, 1)].max() > 0.5\n",
    "    negative_correlations = corr_matrix.values[np.triu_indices_from(corr_matrix.values, 1)].min() < -0.5\n",
    "    zero_correlations = np.any(np.isclose(corr_matrix.values[np.triu_indices_from(corr_matrix.values, 1)], 0, atol=0.1))\n",
    "\n",
    "    print_colored_message(positive_correlations, \"Some columns are positively correlated: True\", \"Some columns are positively correlated: False\")\n",
    "    print_colored_message(negative_correlations, \"Some columns are negatively correlated: True\", \"Some columns are negatively correlated: False\")\n",
    "    print_colored_message(zero_correlations, \"At least two columns have a correlation close to 0: True\", \"At least two columns have a correlation close to 0: False\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Generated Dataset\n",
    "\n",
    "With the above utilities and functions, we will now load the dataset and check if it meets the specified conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m\n",
      "Means:\n",
      "\u001b[0m feature_1     0.986667\n",
      "feature_2     2.427051\n",
      "feature_3     5.172044\n",
      "feature_4    10.329018\n",
      "feature_5    20.493459\n",
      "feature_6    50.303660\n",
      "dtype: float64\n",
      "\u001b[92mAll columns have different means: True\u001b[0m\n",
      "\u001b[95m\n",
      "Standard Deviations:\n",
      "\u001b[0m feature_1     0.529866\n",
      "feature_2     0.944037\n",
      "feature_3     2.019855\n",
      "feature_4     4.047939\n",
      "feature_5     7.508285\n",
      "feature_6    15.967371\n",
      "dtype: float64\n",
      "\u001b[92mAll columns have different standard deviations: True\u001b[0m\n",
      "\u001b[92mAt least one column contains integers: True\u001b[0m\n",
      "\u001b[92mAt least one column contains floats: True\u001b[0m\n",
      "\u001b[92mOne column has a mean close to 2.5: True\u001b[0m\n",
      "\u001b[95m\n",
      "Correlation Matrix:\n",
      "\u001b[0m            feature_1  feature_2  feature_3  feature_4  feature_5  feature_6\n",
      "feature_1   1.000000   0.012291   0.074457   0.043412   0.011114  -0.055734\n",
      "feature_2   0.012291   1.000000   0.049643   0.065258  -0.790640   0.045529\n",
      "feature_3   0.074457   0.049643   1.000000   0.805541  -0.019949   0.093384\n",
      "feature_4   0.043412   0.065258   0.805541   1.000000  -0.030241   0.033181\n",
      "feature_5   0.011114  -0.790640  -0.019949  -0.030241   1.000000  -0.040196\n",
      "feature_6  -0.055734   0.045529   0.093384   0.033181  -0.040196   1.000000\n",
      "\u001b[92mSome columns are positively correlated: True\u001b[0m\n",
      "\u001b[92mSome columns are negatively correlated: True\u001b[0m\n",
      "\u001b[92mAt least two columns have a correlation close to 0: True\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "file_path = 'artificial_dataset.csv'\n",
    "check_dataset_conditions(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have generated an artificial dataset with specified correlations and checked it for a variety of conditions:\n",
    "\n",
    "- Unique means and standard deviations for each column\n",
    "- Presence of both integer and float data types\n",
    "- Specific means close to a given value (e.g., 2.5)\n",
    "- Various types of correlations between columns\n",
    "\n",
    "The utility functions provided us with an automated way to validate these conditions, and the color-coded output helped in quickly assessing the results.\n",
    "\n",
    "### Findings\n",
    "- **Means:** The script confirms whether all columns have different means.\n",
    "- **Standard Deviations:** It checks if all columns have different standard deviations.\n",
    "- **Data Types:** The dataset was verified for at least one integer and one float column.\n",
    "- **Mean Value Check:** The presence of a column with a mean close to 2.5 was validated.\n",
    "- **Correlations:** The dataset was checked for positive, negative, and negligible correlations.\n",
    "\n",
    "The validation process executed indicates whether the dataset adheres to the specified conditions. This kind of automation is crucial in ensuring data quality for downstream analysis and machine learning tasks.\n",
    "\n",
    "**Note:** The color-coding in the output is based on ANSI escape codes and may not render as expected in all Jupyter environments. If the color-coding does not appear in the output, consider adjusting the `bcolors` class or the `print_colored_message` function to be compatible with your specific Jupyter setup or remove the color functionality for universal compatibility.\n",
    "\n",
    "By automating these checks, we can streamline the process of dataset generation and ensure that the data meets the necessary preconditions before it is used for further analysis or model training.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67f1dc6f6f712f7142079021955b91e049abb319dcfdc9eed010dd73dd4d845d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
